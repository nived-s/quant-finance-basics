{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accace1f",
   "metadata": {},
   "source": [
    "# Setup and leakage review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f72e5aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1054/474544344.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start_date, end=end_date)\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base DataFrame loaded. Rows: 1508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "\n",
    "ticker = \"MSFT\"\n",
    "start_date = \"2018-01-01\"\n",
    "end_date = \"2024-01-01\"\n",
    "\n",
    "# Load necessary raw data\n",
    "data = yf.download(ticker, start=start_date, end=end_date)\n",
    "df = data[['Close', 'High', 'Low', 'Volume']].ffill()\n",
    "\n",
    "# Calculate the base return\n",
    "df['Log_Return'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "\n",
    "# Drop first row due to return calculation\n",
    "df = df.dropna()\n",
    "\n",
    "print(\"Base DataFrame loaded. Rows:\", df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f33ef2",
   "metadata": {},
   "source": [
    "Lookahead bias principle: All features must be constructed using data that was known before the prediction time t."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0767e1bb",
   "metadata": {},
   "source": [
    "# Feature scaling and normalization\n",
    "Scaling features ensures that no single feature, due to its large absolute magnitude (e.g., Volume vs. Daily Return), unfairly dominates the model's loss function. This is crucial for Gradient-Based Models (like Neural Networks or Support Vector Machines).\n",
    "\n",
    "## Z-score normalization (standardization)\n",
    "Transforms the feature to have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3014a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy rolling feature(21 day SMA)\n",
    "window = 21\n",
    "df['SMA_21'] = df['Close'].rolling(window=window).mean().shift(1)   # Shift to prevent leakage\n",
    "\n",
    "# Z-score normalization \n",
    "# 1. calc rolling mean\n",
    "rolling_mean = df['SMA_21'].expanding(min_periods=window).mean().shift(1)\n",
    "\n",
    "# 2. calc rolling std\n",
    "rolling_std = df['SMA_21'].expanding(min_periods=window).std().shift(1)\n",
    "\n",
    "# 3. z-score\n",
    "df['SMA_21_Zscore'] = (df['SMA_21'] - rolling_mean) / rolling_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce945d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2023-12-22    0.092417\n",
       "2023-12-26   -0.042680\n",
       "2023-12-27   -0.136839\n",
       "2023-12-28    0.116203\n",
       "2023-12-29    0.052640\n",
       "Name: Log_Return_Zscore, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXAMPLE: zscore the log return\n",
    "return_mean = df['Log_Return'].expanding(min_periods=window).mean().shift(1)\n",
    "return_std = df['Log_Return'].expanding(min_periods=window).std().shift(1)\n",
    "df['Log_Return_Zscore'] = (df['Log_Return'] - return_mean) / return_std\n",
    "\n",
    "df['Log_Return_Zscore'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230afe22",
   "metadata": {},
   "source": [
    "## Min-max\n",
    "Scales the feature to a fixed range, typically [0, 1]. <br>\n",
    "NOTE: When using Min-Max in a real model, the Min and Max values must be computed only from the training dataset and then applied to the validation and test sets. You cannot use the overall minimum/maximum from the entire dataset, as this would incorporate future information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46a9cbb",
   "metadata": {},
   "source": [
    "# Feature transforms and rank\n",
    "## Percentage rank features\n",
    "The percentile rank tells you where the current value stands relative to its past N values (e.g., 95% rank means the current return is higher than 95% of the returns in the last N days). This transforms the raw value into a scale-independent position within its recent history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c77a08c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2023-12-22    0.650794\n",
       "2023-12-26    0.476190\n",
       "2023-12-27    0.365079\n",
       "2023-12-28    0.317460\n",
       "2023-12-29    0.492063\n",
       "Name: Return_Rank_63d, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = 63 # Quarterly rank\n",
    "def rolling_percentile_rank(series, window):\n",
    "    \"\"\"Calculates the rolling percentile rank of the current value.\"\"\"\n",
    "    # Use the current window to compute the rank.\n",
    "    # The result needs to be shifted by 1 to prevent lookahead.\n",
    "    rank_func = lambda x: pd.Series(x).rank(pct=True).iloc[-1]\n",
    "    return series.rolling(window=window).apply(rank_func, raw=False).shift(1)\n",
    "\n",
    "df['Return_Rank_63d'] = rolling_percentile_rank(df['Log_Return'], window=63)\n",
    "df['Return_Rank_63d'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f02eb7",
   "metadata": {},
   "source": [
    "## Reducing heavy tails \n",
    "heavy tails (outliers/extreme returns) can disproportionately influence modles. \n",
    "<br>\n",
    "<br>\n",
    "winsorization : settning returns that are outside a certial percentile (eg 99th) equal to the value of that percentile. this caps the extremes. <br>\n",
    "signed log transform: smooth way to compress larg values while preserving the sign(direction). Transform(x)=sign(x)×ln(1+∣x∣)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08003b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the Signed Log Transform to the raw Log Returns\n",
    "df['Log_Return_SignedLog'] = np.sign(df['Log_Return']) * np.log1p(np.abs(df['Log_Return']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
